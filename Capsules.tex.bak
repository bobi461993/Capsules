\documentclass{beamer}
\mode<presentation>
\usetheme{CambridgeUS}
\usecolortheme{beaver}

\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{url}
\usepackage[backend=bibtex, style=verbose]{biblatex}
\bibliography{bibliography.bib}
\usepackage[noend]{algorithm,algpseudocode}


\title[Dynamic Routing Between Capsules]{Dynamic Routing Between Capsules}
\author[Mu\c sat Bogdan-Adrian]{Authors: Sara Sabour, Nicholas Frosst, Geoffrey E Hinton}
\date{November 2017}

        \beamertemplatenavigationsymbolsempty
\graphicspath{{./images/}}

\begin{document}

\frame{\titlepage}

\begin{frame}
\frametitle{Introduction}
\center
\begin{itemize}
	\item A capsule is a group of neurons whose activity vector represents an entity - either an object or an object part
	\item The length of the vector represents the probability that a certain entity exists
	\item Achieves state-of-the-art performance on MNIST and is better at recognizing highly overlapping digits than a convolutional network
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Reference with human vision}
\center
\begin{itemize}
	\item The human vision processes only a tiny fraction of the optic array at the highest resolution
	\item Assumption that the visual system creates a parse tree (Fig. a) on each fixation
	\begin{figure}
	\subcapcentertrue
    \centering
    	\subfigure[Parse tree example: \newline (7 + 3) * (5 - 2)]
        {\includegraphics[width=0.4\textwidth]{parse_tree.png}}
    \end{figure}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Capsules as parse trees}
\center
\begin{itemize}
	\item A parse tree can be represented by a multilayer neural network
	\item Each layer will be divided into many capsules
	\item Using an iterative routing process, each capsule will choose a capsule in the layer above to be its parent in the tree - this process solves the problem of assigning parts to wholes
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Describing the capsule}
\center
\begin{itemize}
	\item The vector of activities of a capsule represent the various properties of a particular entity that is present in the image (pose, deformation, velocity, texture etc.)
	\item The existence of an object is defined by using the overall length of the activity vector of a capsule - a non-linearity is applied so that the length of the vector output cannot exceed 1
	\item A lower level capsule is assigned to a higher level capsule by a ``routing-by-agreement'' algorithm
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{How the vector inputs and outputs of a capsule are computed}
The length of the output vector of a capsule should represent the probability that the entity represented by the capsule is present in the current input. A non-linear squashing function is used to ensure that short vectors get shrunk to almost zero length and long vectors get shrunk to a length slightly below 0:
\begin{equation}
\begin{split}
v_j = \frac{\lVert s_j \rVert^2}{1 + \lVert s_j \rVert^2} \frac{s_j}{\lVert s_j \rVert^2}
\end{split}
\end{equation}
where \(v_j\) is the vector output of capsule \(j\) and \(s_j\) is its total input.
\end{frame}

\begin{frame}
\frametitle{How the vector inputs and outputs of a capsule are computed}
For all but the first layer of capsules, the total input to a capsule \(s_j\) is a weighted sum over all prediction vectors \(\hat{u}_{j|i}\) from the capsules in the layer below and is produced by multiplying the output \(u_i\) of a capsule in the layer below by a weight matrix \(W_{ij}\):
\begin{equation}
\begin{split}
s_j = \sum_{i}c_{ij}\hat{u}_{i|j}, \ \ \ \hat{u}_{i|j} = W_{ij}u_i
\end{split}
\end{equation}
where the \(c_{ij}\) are coupling coefficients that are determined by the iterative dynamic routing process.
\end{frame}

\begin{frame}
\frametitle{How the vector inputs and outputs of a capsule are computed}
The coupling coefficients between capsule i and all the capsules in the layer above sum to 1 and are determined by a ``routing softmax'' whose initial logits \(b_{ij}\) are the log prior probabilities that capsule \(i\) should be coupled to capsule \(j\):
\begin{equation}
\begin{split}
c_{ij} = \frac{exp(b_{ij})}{\sum_{k}exp(b_{ik})}
\end{split}
\end{equation}
The initial coupling coefficients are iteratively refined by measuring the agreement between the current output \(v_j\) of each capsule, \(j\), in the layer above and the prediction \(\hat{u}_{j|i}\) made by capsule \(i\).
\end{frame}

\begin{frame}
\frametitle{How the vector inputs and outputs of a capsule are computed}
The agreement is simply the scalar product \(a_{ij} = v_j \cdot \hat{u}_{j|i}\). This agreement is treated as if it were a log likelihood and is added to the initial logit, \(b_{ij}\) before computing the new values for all the coupling coefficients linking capsule \(i\) to higher level capsules.
\end{frame}

\begin{frame}
\frametitle{Routing algorithm}
\begin{algorithmic}[1]
\Function{ROUTING}{$\hat{u}_{j|i}, r, l$}
	\State for all capsule $i$ in layer $l$ and capsule $j$ in layer ($l$ + 1): $b_{ij} \gets$ 0.
		\For {$r$ iterations}
			\State for all capsule $i$ in layer $l$: $c_i \gets$ softmax($b_i$)
			\State for all capsule $j$ in layer ($l$ + 1): $s_j \gets \sum_{i}c_{ij}\hat{u}_{j|i}$
			\State for all capsule $j$ in layer ($l$ + 1): $v_j \gets$ squash($s_j$)
			\State for all capsule $i$ in layer $l$ and capsule $j$ in layer ($l$ + 1): 
			\State \ \ \ \ $b_{ij} \gets b_{ij} + \hat{u}_{j|i} \cdot v_j$
		\EndFor
		\Return $v_j$
\EndFunction
\end{algorithmic}
\end{frame}

\begin{frame}
\frametitle{Margin loss for digit existence}
Because the length of the instantiation vector is used to represent the probability that a capsule's entity exists, the top-level capsule for digit class k should have a long vector if and only if that digit is present in the image. For multiple digits, a margin loss is used:
\begin{equation}
\begin{split}
L_c = T_c max(0, m^+ - \lVert v_c \rVert)^2 + \lambda (1 - T_c) max(0, \lvert v_c \rVert - m^-)^2
\end{split}
\end{equation}
where \(T_c = 1\) iff a digit of class \(c\) is present and \(m^+ = 0.9\) and \(m^- = 0.1\). The \(\lambda\) down-weighting of the loss for absent digit classes stops the initial learning from shrinking the lengths of the activity vectors of all the digit capsules. The total loss is simply the sum of the losses of all digit capsules.
\end{frame}

\begin{frame}
\frametitle{CapsNet architecture}
\begin{figure}
	\subcapcentertrue
    \centering
    	\subfigure[CapsNet architecture]
        {\includegraphics[width=1.0\textwidth]{capsnet.png}}
    \end{figure}
   
\begin{itemize}
	\item Shallow network with only two convolutional layers and one fully connected layer (Fig. b)
	\item Routing is implemented only between PrimaryCaps and DigitCaps layers
\end{itemize}    
\end{frame}

\begin{frame}
\frametitle{Reconstruction as a regularization method}
\begin{figure}
	\subcapcentertrue
    \centering
    	\subfigure[Reconstruction from a capsule representation]
        {\includegraphics[width=0.6\textwidth]{reconstruction.png}}
    \end{figure}
   
An additional reconstruction loss is used to encourage the digit capsules to encode the instantiation parameters of the input digit. The output of the correct digit capsule is fed into a decoder consisting of 3 fully connected layers that model the pixel intensities (Fig. c). The objective function is the sum of squared differences between the outputs of the logistic units and the pixel intensities. This loss is scaled by 0.0005 so that it does not dominate the margin loss during training.
\end{frame}

\begin{frame}
\frametitle{Reconstruction results}
\begin{figure}
	\subcapcentertrue
    \centering
    	\subfigure[Digits reconstructed from the output of a capsule]
        {\includegraphics[width=1.0\textwidth]{reconstruction_results.png}}
    \end{figure}
\end{frame}

\begin{frame}
\frametitle{Results on MNIST}
\begin{figure}
	\subcapcentertrue
    \centering
    	\subfigure[Comparations between different network configurations and a CNN baseline]
        {\includegraphics[width=0.9\textwidth]{comparation.png}}
    \end{figure}
The baseline is a standard CNN with three convolutional layers of 256, 256, 128 channels. Each has 5x5 kernels and stride of 1. The last convolutional layer is followed by two fully connected layers of size 328, 192. The last fully connected layers is connected with dropout to a 10 class softmax layer with cross entropy loss.
\end{frame}

\begin{frame}
\frametitle{What the individual dimensions of a capsule represent}
\begin{itemize}
	\item The dimensions of a digit capsule should learn to span the space of variations in the way digits of that class are instantiated (stroke thickness, skew and width)
	\item To see what the individual dimensions represent, a perturbed output vector can be fed to the decoder network to see how the perturbation affects the reconstruction (Fig. f)
\end{itemize}
\begin{figure}
    \centering
    	\subfigure[Dimension peturbations]
        {\includegraphics[width=0.75\textwidth]{perturbed.png}}
    \end{figure}
\end{frame}

\begin{frame}
\frametitle{Robustness to Affine Transformations}
\begin{itemize}
	\item Experiments show that each DigitCaps capsule learns a more robust representation for each class than a traditional convolutioanl network
	\item To test the robustness of CapsNet to affine transformations, a training was done on a padded and translated MNIST set, in which each example is an MNIST digit placed randomly on a black 				  background
	\item The network was tested on the affNIST \footcite{affNIST} data set, in which each example is an MNIST digit with a random small affine transformation
	\item CapsNet achieved 79\% accuracy, while a tranditional convolutional model with a similar number of parameters only 66\%
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Segmenting highly overlapping digits}
\begin{itemize}
	\item Dynamic routing can be viewed as a parallel attention mechanism that allows each capsule at one level to attend to some active capsules at the level below and to ignore others; This should allow the model to recognize multiple object in the image even if objects overlap
	\item To test this assumption, the MultiMNIST dataset was created by overlaying a digit on top of another from the same set, but different class, having 80\% average overlap
	\item During reconstruction, a digit is picked one at a time and use the activity vector of the chosen digit capsule to reconstruct the image of the chosen digit (Fig. g)
	\item The fact that it is able to reconstruct digits regardless of the overlap shows that each digit capsule can pick up the style and position from the votes it is receiving from PrimaryCapsules layer
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Segmenting highly overlapping digits}
\begin{figure}
    \centering
    	\subfigure[Sample reconstruction of a CapsNet on MultiMNIST test dataset]
        {\includegraphics[width=0.75\textwidth]{segmenting.png}}
    \end{figure}
\end{frame}

\begin{frame}
\frametitle{Other datasets}
\begin{itemize}
	\item On CIFAR10, the network achieved 10.6\% error with an ensemble of 7 models; 10.6\% test error is about what standard convolutional nets achieved when they were first applied to CIFAR10 \footcite{DBLP:journals/corr/abs-1301-3557}
	\item The network was also tested on smallNORB \footcite{LeCun:2004:LMG:1896300.1896315} and achieved 2.7\% test error rate, which is in-par with the state-of-the-art \footcite{DBLP:journals/corr/abs-1102-0183}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Conclusion}
\begin{itemize}
	\item Convolutional neural networks suffer from the difficulty of generalizing to novel viewpoints. Capsules avoid this issue by converting pixel intensities into vectors of instantiation parameters of recognized fragments and then applying transformation matrices to the fragments to predict the instantiation parameters of larger fragments. Transformation matrices that learn to encode the intrinsic spatial relationship between a part and a whole constitute viewpoint invariant knowledge that automatically generalizes to novel viewpoints.
	\item Capsules can deal with multiple different affine transformations of different objects or object parts at the same time; they are also very good for dealing with segmentation.
	\item Research on capsules is now at a similar stage to research on recurrent neural networks for speech recognition at the beginning of this century.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Public implementations}
\begin{itemize}
	\item Tensorflow: \url{https://github.com/naturomics/CapsNet-Tensorflow}
	\item Pytorch: \url{https://github.com/gram-ai/capsule-networks}
	\item Keras: \url{https://github.com/XifengGuo/CapsNet-Keras}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Further research}
\begin{itemize}
	\item ICLR 2018 blind submission - Matrix Capsules With EM Routing \footnote{https://openreview.net/pdf?id=HJWLfGWRb}
	\begin{itemize}
		\item Uses a matrix instead of a vector as the instantiation parameters of a capsule
		\item Uses the EM algorithm to iteratively update the coupling coefficients
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Technical slides - How PrimaryCaps is computed?}
There are two ways to obtain a convolutional capsule from the output of a traditional convolution:
\begin{itemize}
	\item Perform 8 separate traditional convolutions (each with 32 filters), reshape the output of each of these convolutions to a tensor of \((32 * 6 * 6)x1\), and then concatenate all those tensors along the last axis to obtain a tensor of dimension \((32 * 6 * 6)x8\); the interpretation of this output is that there are \(32 * 6 * 6\) capsules, each being an \(8D\) vector.
	\item Perform a single convolution with \(32 * 8\) filters and then reshape the output into a tensor of dimension \((32 * 6 * 6)x8\)
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Technical slides - When is the routing procedure applied?}
\begin{itemize}
\item The routing procedure is applied when computing the feedforward activities through the network and only between the PrimaryCaps and DigitCaps layers. The coupling coefficients are determined by using the routing mechanism, for the backpropagation phase remaining only the transformation matrices \(W_{ij}\) to be computed. The training is done in a classical way, by using the Adam optimizer, the routing module being fully differentiable.
\end{itemize}
\end{frame}

\end{document}
